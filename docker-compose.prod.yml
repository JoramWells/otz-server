services:

  zookeeper:
    image:  confluentinc/cp-zookeeper:latest
    healthcheck:
      test: nc -z localhost 2181 || exit -1
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    restart: on-failure
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - ./log4j.properties:/conf/log4j.properties
    networks:
      - otz

  kafka:
    image: confluentinc/cp-kafka:latest
    ports:
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # KAFKA_LOG_DIRS: /kafka/logs

    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    healthcheck:
      test: ["CMD-SHELL", "bash", "-c", "kafka-topics --bootstrap-server broker:9092 --list"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      zookeeper:
        condition: service_healthy
    networks:
      - otz

  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
    environment:
      - ALLOW_EMPTY_PASSWORD=yes 
    networks:
      - otz   
    volumes:
      - redis_data:/data

  database:
    image: postgres:alpine
    # environment:
    #   POSTGRES_DB: "otz"
    #   POSTGRES_USER: "postgres"
    #   POSTGRES_PASSWORD: "postgres"
    env_file:
      - .env
    ports:
      - 5432:5432
    volumes:
      # - postgres_data:/var/lib/postgresql/data
      # - ./otz_query.sql:/docker-entrypoint-initdb.db/otz_query.sql

      - ./otzv5.sql:/docker-entrypoint-initdb.d/otzv5.sql

    # entrypoint: ["sh", "-c", "sleep 10 && psql -U ${POSTGRES_USER} -d ${POSTGRES_DB} -f /docker-entrypoint-initdb.d/otz_query.sql"]

 

    deploy:
      # mode: replicated
      # replicas: 2
      # placement:
      #   max_replicas_per_node: 1
      # update_config:
      #   parallelism: 2
      #   delay: 10s
      restart_policy:
        condition: always    
      # resources:
      #   limits:
      #     cpus: '0.10'
      #     memory: 400M
      #   reservations:
      #     cpus: '0.10'
      #     memory: 400M
    networks:
      - otz
    healthcheck:
      test: "pg_isready --username=${POSTGRES_USER} && psql --username=${POSTGRES_USER} --list"
      interval: 5s
      timeout: 10s
      retries: 10 

  # db_initializer:
  #   image: postgres:alpine
  #   depends_on:
  #     database:
  #       condition: service_healthy
  #   env_file:
  #     - .env
  #   volumes:
  #     - ./otz_query.sql:/docker-entrypoint-initdb.db/otz_query.sql
    
  #   entrypoint: ["sh", "-c", "sleep 10 && psql -U ${POSTGRES_USER} -d ${POSTGRES_DB} -f /docker-entrypoint-initdb.d/otz_query.sql"]
    # environment:
    #   PGPASSWORD: ${POSTGRES_PASSWORD}
  etl:
    build:
      context: ./etl_webapp
      dockerfile: Dockerfile
    command: python manage.py runserver 0.0.0.0:8002
    volumes:
      - ./etl_webapp:/etl_webapp
      # - /etl_webapp
    depends_on:
      database:
        condition: service_healthy
      redis:
        condition: service_started
    networks:
      - otz
    ports:
      - 8002:8002 

  # user_db:
  #   image: postgres:alpine
  #   # environment:
  #   #   POSTGRES_DB: "otz-users"
  #   #   POSTGRES_USER: "postgres"
  #   #   POSTGRES_PASSWORD: "postgres"
  #   env_file:
  #   - .env
  #   ports:
  #   - 5437:5432
  #   volumes:
  #   # - postgres_data:/var/lib/postgresql/data
  #   - ./users_backup.sql:/docker-entrypoint-initdb.d/users_backup.sql


  #   deploy:
  #   #   mode: replicated
  #   #   replicas: 2
  #   #   placement:
  #   #     max_replicas_per_node: 1
  #   #   update_config:
  #   #     parallelism: 2
  #   #     delay: 10s
  #   # restart_policy:
  #   #   condition: on-failure    
  #   #   resources:
  #   #     limits:
  #   #       cpus: '0.20'
  #   #       memory: 450M
  #   #     reservations:
  #   #       cpus: '0.20'
  #   #       memory: 450M
  #   networks:
  #   - otz
  #   healthcheck:
  #     test: "pg_isready --username=${POSTGRES_USER} && psql --username=${POSTGRES_USER} --list"
  #     interval: 5s
  #     timeout: 10s
  #     retries: 10    

  users:
    build:
      context: ./src/Users
      dockerfile: Dockerfile
    image: blackwell18/users:latest
    volumes:
      - ./src/Users/:/usr/src/app
      - /usr/src/app/node_modules
    deploy:
      # mode: replicated
      # replicas: 2
      # placement:
      #   max_replicas_per_node: 1
      # update_config:
      #   parallelism: 2
      #   delay: 10s
      # restart_policy:
      #   condition: on-failure    
      resources:
        limits:
          cpus: '0.30'
          memory: 700M
        reservations:
          cpus: '0.30'
          memory: 700M
    ports:
      - 5001:5001
    depends_on:
      database:
        condition: service_healthy
      redis:
        condition: service_started  
    networks:
      - otz

  lab:
    build:
      context: ./src/Lab
      dockerfile: Dockerfile
    image: blackwell18/lab:latest
    volumes:
      - ./src/Lab/:/usr/src/app
      - /usr/src/app/node_modules
    deploy:
      # mode: replicated
      # replicas: 2
      # placement:
      #   max_replicas_per_node: 1
      # update_config:
      #   parallelism: 2
      #   delay: 10s
      # restart_policy:
      #   condition: on-failure    
      resources:
        limits:
          cpus: '0.30'
          memory: 700M
        reservations:
          cpus: '0.30'
          memory: 700M
    ports:
      - 5002:5002
    depends_on:
      database:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - otz

  pharmacy:
    build:
      context: ./src/Pharmacy
      dockerfile: Dockerfile
    image: blackwell18/pharmacy:latest
    volumes:
      - ./src/Pharmacy/:/usr/src/app
      - /usr/src/app/node_modules
    deploy:
      # mode: replicated
      # replicas: 2
      # placement:
      #   max_replicas_per_node: 1
      # update_config:
      #   parallelism: 2
      #   delay: 10s
      # restart_policy:
      #   condition: on-failure    
      resources:
        limits:
          cpus: '0.30'
          memory: 700M
        reservations:
          cpus: '0.30'
          memory: 700M   
    ports:
      - 5003:5003
    depends_on:
      database:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - otz  

  # medicalfile:
  #   build:
  #     context: ./src/MedicalFile
  #     dockerfile: Dockerfile
  #   image: blackwell18/medicalfile:latest
  #   volumes:
  #     - ./src/MedicalFile/:/usr/src/app
  #     - /usr/src/app/node_modules
  #   deploy:
  #     # mode: replicated
  #     # replicas: 2
  #     # placement:
  #     #   max_replicas_per_node: 1
  #     # update_config:
  #     #   parallelism: 2
  #     #   delay: 10s
  #     # restart_policy:
  #     #   condition: on-failure    
  #     resources:
  #       limits:
  #         cpus: '0.30'
  #         memory: 700M
  #       reservations:
  #         cpus: '0.30'
  #         memory: 700M   
  #   ports:
  #     - 5006:5006
  #   depends_on:
  #     database:
  #       condition: service_healthy
  #   networks:
  #     - otz  

  root:
    build:
      context: ./src/root
      dockerfile: Dockerfile
    image: blackwell18/root:latest
    volumes:
      - ./src/root:/usr/src/app
      - /usr/src/app/node_modules
    deploy:
      # mode: replicated
      # replicas: 2
      # placement:
      #   max_replicas_per_node: 1
      # update_config:
      #   parallelism: 2
      #   delay: 10s
      # restart_policy:
      #   condition: on-failure    
      resources:
        limits:
          cpus: '0.30'
          memory: 800M
        reservations:
          cpus: '0.30'
          memory: 800M  
    ports:
      - 5000:5000
    depends_on:
      database:
        condition: service_healthy
      redis:
        condition: service_started

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/users/fetchAll"]
      interval: 1m30s
      timeout: 10s
      retries: 3
      start_period: 2m    
    networks:
      - otz

  # school:
  #   build:
  #     context: ./src/School
  #     dockerfile: Dockerfile
  #   image: school-image
  #   volumes:
  #     - ./src/School:/usr/src/app
  #     - /usr/src/app/node_modules

  #   deploy:
      # mode: replicated
      # replicas: 2
      # placement:
      #   max_replicas_per_node: 1
      # update_config:
      #   parallelism: 2
      #   delay: 10s
      # restart_policy:
      #   condition: on-failure    
    #   resources:
    #     limits:
    #       cpus: '0.40'
    #       memory: 700M
    #     reservations:
    #       cpus: '0.40'
    #       memory: 700M   
    # ports:
    #   - 5004:5004
    # depends_on:
    #   database:
    #     condition: service_healthy
    #   # - kafka-2
    # networks:
    #   - otz

  appointment:
    build:
      context: ./src/Appointment
      dockerfile: Dockerfile
    image: blackwell18/appointment:latest
    volumes:
      - ./src/Appointment:/usr/src/app
      - /usr/src/app/node_modules
    deploy:
      # mode: replicated
      # replicas: 2
      # placement:
      #   max_replicas_per_node: 1
      # update_config:
      #   parallelism: 2
      #   delay: 10s
      # restart_policy:
      #   condition: on-failure    
      resources:
        limits:
          cpus: '0.30'
          # memory: 800M
        reservations:
          cpus: '0.30'
          # memory: 700M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5005/appointments/fetchAll"]
      interval: 1m30s
      timeout: 10s
      retries: 3
      start_period: 2m       
    ports:
      - 5005:5005
    depends_on:
      database:
        condition: service_healthy
      kafka:
        condition: service_started
      redis:
        condition: service_started    
    networks:
      - otz

  notify:
    build:
      context: ./src/Notify
      dockerfile: Dockerfile
    image: blackwell18/notify:latest
    volumes:
      - ./src/Notify:/usr/src/app
      - /usr/src/app/node_modules
    deploy:
      # mode: replicated
      # replicas: 2
      # placement:
      #   max_replicas_per_node: 1
      # update_config:
      #   parallelism: 2
      #   delay: 10s
      # restart_policy:
      #   condition: on-failure    
      resources:
        limits:
          cpus: '0.30'
          # memory: 750M
        reservations:
          cpus: '0.30'
          # memory: 750M
    healthcheck:
      test: ["CMD-SHELL", "curl", "-f", "http://localhost:5005/appointments/fetchAll"]
      interval: 1m30s
      timeout: 10s
      retries: 3
      start_period: 2m       
    ports:
      - 5008:5008
    depends_on:
      database:
        condition: service_healthy
      kafka:
        condition: service_healthy
      redis:
        condition: service_started    
    networks:
      - otz   

  # client:
  #   build:
  #     context: ../client
  #     dockerfile: Dockerfile
  #   image: otz-client
  #   # container_name: huruma-frontendv2
  #   volumes:
  #     - ../client:/usr/src/app
  #     - /usr/src/app/node_modules

  #   deploy:
  #     # mode: replicated
  #     # replicas: 5
  #     # placement:
  #     #   max_replicas_per_node: 1
  #     # update_config:
  #     #   parallelism: 2
  #     #   delay: 10s
  #     # restart_policy:
  #     #   condition: on-failure    
  #     resources:
  #       limits:
  #         cpus: '0.40'
  #         # memory: 1000M

  #   ports:
  #     - "3000:3000"
  #   depends_on:
  #     - users
  #     - school
  #     - lab
  #     - root
  #     - appointment  
  #     - pharmacy  
  #   networks:
  #     - otz

  articles:
    build:
      context: ./src/Articles
      dockerfile: Dockerfile
    image: blackwell18/articles:latest
    volumes:
      - ./src/Articles:/usr/src/app
      - /usr/src/app/node_modules
    deploy:
      # mode: replicated
      # replicas: 2
      # placement:
      #   max_replicas_per_node: 1
      # update_config:
      #   parallelism: 2
      #   delay: 10s
      # restart_policy:
      #   condition: on-failure    
      resources:
        limits:
          cpus: '0.35'
          memory: 600M
        reservations:
          cpus: '0.35'
          memory: 600M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5005/appointments/fetchAll"]
      interval: 1m30s
      timeout: 10s
      retries: 3
      start_period: 2m       
    ports:
      - 5009:5009
    depends_on:
      database:
        condition: service_healthy
      # - kafka-2
      redis:
        condition: service_started    
    networks:
      - otz

  nginx:
    image: nginx:alpine
    volumes:
      - ./nginx/nginx.prod.conf:/etc/nginx/conf.d/default.conf
      # - ./nginx/ssl:/etc/nginx/ssl
      - ./ssl/otzplus.crt:/etc/ssl/otzplus.crt
      - ./ssl/otzplus.key:/etc/ssl/otzplus.key
      - ./ssl/www_otzplus_xyz.crt:/etc/ssl/www_otzplus_xyz.crt
      - ./ssl/www_otzplus_xyz_chain.crt:/etc/ssl/www_otzplus_xyz_chain.crt
    ports:
      - 80:80
      - 443:443
    # deploy:
    #   mode: replicated
    #   replicas: 2
    #   placement:
    #     max_replicas_per_node: 1
    #   update_config:
    #     parallelism: 2
    #     delay: 10s
    #   restart_policy:
    #     condition: on-failure    
    #   resources:
    #     limits:
    #       cpus: '0.05'
    #       # memory: 700M
    #     reservations:
    #       cpus: '0.05'
    #       # memory: 700M 

    depends_on:
      - articles
      - users
      - root
      # - school
      - lab
      - appointment 
      # - medicalfile   
      - notify
      - pharmacy  
      - etl

    networks:
      - otz

    # entrypoint: ["/bin/sh", "-c", "/usr/share/nginx/client.sh && exec nginx -g 'daemon off;'"]
    # command: sh -c "chmod +x /usr/share/nginx/client.sh && /usr/share/nginx/client.sh && nginx -g 'daemon off;'"

  

networks:
 otz:
  driver: bridge

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local